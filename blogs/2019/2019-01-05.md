
# **No.19001 Docker 基础设施中的API服务器**

------

## api-server-for-docker-infrastructure

[英文原文](https://engineering.docker.com/2019/02/api-server-for-docker-infrastructure/)

    微服务架构可能难以实现。你如何达到特定的服务？您如何确保流量分布在该服务的所有实例上？在云环境中会发生什么情况，作为日常运营的一部分，丢失和获取服务实例是正常的？当您甚至不知道服务运行的位置时，如何配置能够始终如一地路由到您的服务的东西？这些问题的一个可能解决方案是API服务器。在Docker，我们**在HAProxy之上开发了我们自己的高可用性和自动化API服务器，并与Consul进行了深度集成**。我们的**API服务器充当服务发现和负载平衡服务**（API 网关？？），以确保在高度动态的环境中的可用性。在我们深入了解我们创建的内容之前，让我们回顾一下服务发现和负载平衡对我们意味着什么。

### **背景**

    服务发现可确保在某处可以准确查看可用于处理流量的服务列表。然后，任何事情都可以向服务发现机制询问环境中的其他工作负载。我们使用  Consul  进行服务发现。为确保Consul始终了解运行容器的最新信息，我们 在基础架构中的每个节点上运行  Registrator。

    负载平衡是一种提供访问服务发现系统中注册的服务的一致且可靠方式的机制。它跨越类似实例传播传入请求，同时确保始终将请求发送到正常的服务实例。为此，我们使用  HAProxy。它允许我们设置黑名单，白名单，实例之间的对等，以及基于  Host标题或URL路径的路由。作为额外奖励，它为我们提供了丰富的指标来监控系统。在Consul Template的帮助下  ，我们可以将静态配置与Consul提供的动态容器列表合并在一起。

    总之，这些服务允许我们将所有请求发送到HAProxy集群，并让它确定发送请求的确切位置，以确保它得到满足。发送请求的服务无需担心目标服务的位置，是否可以访问它，以及有多少实例。所有请求者需要知道的是HAProxy将代表它完成请求。

    在Docker，当我们考虑API服务器应该为用户做什么时，我们会想到以下用户故事/场景。

- 作为消费服务，我希望能够轻松联系其他服务，而无需知道它们的位置
- 作为消费服务，我发送的任何请求都**不得**路由到挂掉的容器
- 作为消费服务，我发送的任何请求都**不得**路由到挂掉的HAProxy实例
- 作为消费服务，即使提交了无效的HAProxy配置，我发送的任何请求也必须继续工作
- 作为消费服务， 如果API服务器需要应用新配置，我应该注意到**最小的**服务中断/宕机时间
- 作为一名工程师，我**必须能够配置HAProxy**，以便它可以路由到我的服务
- 作为一名工程师，我不想学习一种新的内部配置语言
- 作为一名工程师，我希望能够以最小的*代价*更新我的路由配置

### **总体架构**

    为了满足这些用户故事要求，我们创建了以下总体架构，以确保API服务器的最大正常运行时间。

![仪表板](https://davidsche.github.io/blogs/images/api_server_docker_infra_2-930x1024.png)

    关于这个图，我想指出一些事情。首先，我们使用Amazon Classic Elastic Load Balancers 来支持我们的所有流量。这有一个我们处理HTTP和TCP流量特定的原因，我们希望相同的API服务器能够处理从一个服务到另一个服务，从Web UI或从一个服务到数据库的Web请求。新版本的Amazon负载均衡器，网络负载均衡器和应用程序负载均衡器不提供此选项。我们使用Amazon ELB的另一个原因是它为我们提供了一个易用的通用服务接入点，来指向服务。由于我们的HAProxy集群基于负载动态扩展，因此我们无法将DNS记录直接指向这些节点的IP地址。

    其次，请注意我们的API服务器解决方案将路由到几乎在任何地方运行的服务,使用Docker Enterprise Edition，我们可以在Kubernetes和Docker Swarm中运行服务，但我们也会在没有 orchestrator 的情况下主动运行容器。我们的API服务解决方案将路由到Kubernetes pods，Docker Swarm服务实例或在EC2实例上运行的Docker容器实例-只要Registrator在节点上运行，容器就会被提取并在Consul中注册。

### **核心组件**

![仪表板](https://davidsche.github.io/blogs/images/api_server_docker_infra_3-525x1024.png)

### **配置自动化**

    在工作流程的开始，**工程师**进行配置更改并向我们的**git**存储库打开一个pull请求，这是一个规范的配置源  - 我们恰好使用**GitHub**作为我们的git存储库托管。每次将新提交推送到**master**分支时，我们都会触发  **Jenkins**  自动构建，该构建运行脚本以将最新配置文件推送到**Amazon S3**。这是每个HAProxy实例从中获取配置的中间存储系统。

    然后，我们的  S3 Reload 组件从中间存储系统中提取HAProxy配置模板。这一切都按照定时计划完成。它的最后一个目的是将配置文件放在Consul  Template正在寻找模板更改的特定目录中。

    Consul Template  在定时计划中检查新模板更改，同时还检查Consul键/值更改。它呈现HAProxy模板以及HAProxy运行所必需的一些其他模板（geoip阻止，IP白名单/黑名单，logstash配置等）。最后，Consul Template将已呈现的配置文件放入Logstash  Engine和HAProxy使用的已知目录中。

    流程的关键是 HAProxy确保最终的呈现配置文件有效，同时重新启动提供TCP/HTTP流量的主要进程。在v1.8中我们进行了无缝重新加载，但在所有较低版本的HAProxy中，我们只进行重新加载，这可能导致重试请求出现轻微的峰值。最后，HAProxy还会填充有关配置验证和检查要使用的度量标准管道的指标。

    由于HAProxy仅支持Syslog日志输出，因此我们 使用**Syslog**输入运行**Logstash**，并将日志通过其余的日志记录管道发送。**Logstash**的另一个重要目的是将所有日志复制到主机以便通过Mtail进行解析，这会/metrics在端口上生成3803 Prometheus要抓取的端点  。

    HAProxy Exporter 还根据从抓取HAProxy统计信息页面收集的指标/metrics 在端口9101上生成端点。这些指标不像Mtail生成的指标那样具体，并且彼此不重叠。

    Logrotate  是我们特定于主机的日志管理的一部分，它 确保我们不会耗尽空间，同时确保我们始终在主机上压缩日志的最后一天，以防日志管道发生任何事情。

    最后，尽管不是HAProxy的核心部分，但 **Node Exporter** 包含文本文件收集器，它允许我们将文件添加到目录中，并将这些文件内容导出为Prometheus的端点以进行刮擦。这允许我们公开指标（由HAProxy组件创建），表示我们上次更新HAProxy配置的时间以及HAProxy配置检查是否仍在通过。

### **迁移到容器**

    多年来，我们对HAProxy和Consul的结合对我们来说运作良好，但与许多其他正在进行项目的组织一样，我们在HAProxy版本和技术债务方面落后了。我们确定我们需要从运行无组织的shell脚本集合转变为以容器为中心的解决方案，重点是可维护性，可靠性和可伸缩性。我们迁移的目标包括使用我们自己的软件Docker Enterprise Edition来运行我们基础架构中最重要的部分之一，同时还可以提高灵活性，以便对配置自动化管道中的任何组件进行更改。

![仪表板](https://davidsche.github.io/blogs/images/api_server_docker_infra_4-991x1024.png)

    大多数组件的工作方式与之前的工作方式大致相同，但是一些重大更改使得此设置对更改更具弹性。

    首先，在上图中标记为“POD”的这个计算单元是部署为Kubernetes DaemonSet的Kubernetes Pod。Kubernetes提供控制器以确保整体服务始终处于运行状态，同时还可以保存部署期间发生的情况。

    其次，每个组件只关心输入和输出，而在进程可能重新启动另一个进程以启动配置自动化管道中的下一步之前。我们可以通过几种不同的方式完成此任务，但我们决定采用基于拉的执行模型。大多数输入和输出都是位于共享卷中的文件。在少数情况下，HTTP端点是pod中两个容器之间的契约。 这些更改使调试更容易，因为操作员可以查看文件所处的状态，以确定问题可能发生的位置。 此外，更容易对系统进行更改，因为组件之间的契约是明确的。

    最后，HAProxy升级到1.8，现在支持  真正的无缝重装！

### **结论**

    Registrator，Consul，Consul Template，HAProxy，Mtail，HAProxy Exporter，Node Exporter，Logstash，Prometheus ......在Docker中，所有这些技术都被编织在一起，以提供一个内聚的，自动化的，动态的，高度可用的API服务器。该解决方案使用通用配置语言（HAProxy配置语言）和Go模板（Consul Template），为Docker的工程师提供自助服务路由和负载平衡平台。它还可确保在任何管道出现故障或配置不良的情况下最短的停机时间。HAProxy也是我们基础架构的最后一块，需要转换为在Docker容器中运行。我们现在能够比以前更快地更改负载平衡和服务发现系统，

