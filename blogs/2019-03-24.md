# Docker Swarm系列  Docker Swarm中的日志处理

## 构建自己的容器云PaaS--Docker Swarm中的日志处理实践

这篇文章介绍了Docker Swarm中的日志处理 。

[出处](https://github.com/fluent/fluent-bit/issues/388)

### 通过设置fluent-bit 全局服务，收集系统日志

#### 第一步: create a dedicated volume to host fluent-bit UNIX socket on every docker swarm node:

``` bash
sudo su -
mkdir /tmp/fluent-bit
chmod 777 /tmp/fluent-bit/
chmod o+t /tmp/fluent-bit/
```

#### 第二步: create your own fluent-bit docker image with the following fluent-bit.conf file:

``` conf
[SERVICE]
    Flush        1
    Daemon       Off
    Log_Level    debug
    Log_File     /fluent-bit/log/fluent-bit.log
    Parsers_File parsers.conf
    Parsers_File parsers_java.conf

[INPUT]
    Name         forward
    unix_path    /tmp/fluent-bit/sock

[OUTPUT]
    Name         file
    Match        *
    Path         /tmp/output.txt
```

Use command docker build -t fluent/fluent-bit:0.13-unix-sock ./ as explained in image documentation

#### 第三步: create file fluent-bit-compose.yml as below:

``` yml
version: "3.3"

services:
    forwarder:
        image: fluent/fluent-bit:0.13-unix-sock
        deploy:
            mode: global
        volumes:
            - /tmp/fluent-bit:/tmp/fluent-bit
```

Step 4: deploy it as stack "log": docker stack deploy -c fluent-bit-compose.yml log

If everything is OK, you will have a running service (and container) on every swarm node.

Step 5: check fluent-bit is up and running:

``` bash
tiian@ubuntu001:~/fluent-bit/0.13$ ls -la /tmp/fluent-bit/
total 8
drwxrwxrwt 2 root root 4096 Aug 24 08:02 .
drwxrwxrwt 9 root root 4096 Aug 24 08:04 ..
srwxr-xr-x 1 root root    0 Aug 24 08:02 sock
tiian@ubuntu001:~/fluent-bit/0.13$ docker container ls
CONTAINER ID        IMAGE                              COMMAND                  CREATED             STATUS              PORTS               NAMES
8c39967abdd5        fluent/fluent-bit:0.13-unix-sock   "/fluent-bit/bin/flu…"   2 minutes ago       Up 2 minutes        2020/tcp            log_forwarder.l3yzhsv1e32rbaa7gpcn4wczf.1xjg6x1gad1uxnsnmn8ejenvp
tiian@ubuntu001:~/fluent-bit/0.13$ docker exec -ti 8c39967abdd5 bash
root@8c39967abdd5:/# cat /fluent-bit/log/fluent-bit.log
[2018/08/24 08:02:26] [ info] [engine] started (pid=1)
[2018/08/24 08:02:26] [ info] [in_fw] listening on unix:///tmp/fluent-bit/sock
[2018/08/24 08:02:26] [debug] [router] input=forward.0 'DYNAMIC TAG'
```

Step 6: send a log message from another container (in the same host):

``` bash
tiian@ubuntu001:~$ docker run --log-driver=fluentd --log-opt "fluentd-address=unix:///tmp/fluent-bit/sock" -ti busybox echo test
test
```

Step 7: check the log message (from inside fluent-bit container, see step 5):

``` bash
root@8c39967abdd5:/# cat /fluent-bit/log/fluent-bit.log
[2018/08/24 08:02:26] [ info] [engine] started (pid=1)
[2018/08/24 08:02:26] [ info] [in_fw] listening on unix:///tmp/fluent-bit/sock
[2018/08/24 08:02:26] [debug] [router] input=forward.0 'DYNAMIC TAG'
[2018/08/24 08:07:48] [debug] [input forward.0] [mem buf] size = 140
[2018/08/24 08:07:48] [debug] [task] created task=0x7f691d24b0e0 id=0 OK
[2018/08/24 08:07:48] [debug] [task] destroy task=0x7f691d24b0e0 (task_id=0)
[2018/08/24 08:07:48] [debug] [dyntag forward.0] 0x7f691d29b060 destroy (tag=bae234087c7c, bytes=140)
root@8c39967abdd5:/# cat /tmp/output.txt
bae234087c7c: [1535098068.000000, {"log":"test\r", "container_id":"bae234087c7c14fe7156ab620950de338b657a0674d94f4364719e4a80685883", "container_name":"/serene_easley", "source":"stdout"}]
```

Summary

You can deploy a fluent-bit forwarder in all the nodes of a swarm cluster and collect logging from docker containers that send logs to a dedicated UNIX socket /tmp/fluent-bit/sock.

Of course, fluent-bit forwarders can send collected logs to any supported destination, /tmp/output.txt is just for the sake of easyness.

-----

其他参考

[docker swarm 环境中的127.0.0.1问题](https://github.com/moby/moby/issues/32299)
Docker Logging with Fluent Bit and Elasticsearch

[Docker Logging with Fluent Bit and Elasticsearch](https://fluentbit.io/articles/docker-logging-elasticsearch/)
Configuring Kibana and ElasticSearch for Log Analysis with Fluentd on Docker Swarm

[Configuring Kibana and ElasticSearch for Log Analysis with Fluentd on Docker Swarm](http://littlebigextra.com/using-kibana-and-elasticsearch-for-log-analysis-with-fluentd-on-docker-swarm/)

[k8s](https://blog.giantswarm.io/giantswarm-vs-openshift/)