# 理解Nomad中的网络
## Understanding Networking in Nomad

Nomad 是一个通用的群集业务流程编排（协调）程序和调度（计划）程序。
在Nomad 1.3发布之前，它没有本机支持发现集群中运行的其他应用程序。这是在集群中计划任务时非常基本的要求。
Nomad依靠Consul来发现其他“服务”，并在注册和获取服务记录方面拥有一流的支持，这使事情变得更加容易。
Consul 通过各种机制（如 REST API、DNS 和 Consul 模板）提供记录，
这些机制在 Go 模板中呈现服务的确切 IP/端口， 该模板可以注入到您的应用程序中。

我已经使用Nomad很长一段时间了（无论是在工作中还是在我的自托管实例中），但是当涉及到网络时，我经常跳闸。
Nomad有很多简单的概念，一旦你理解并认识到可用于连接应用程序的各种模式，它们就会“点击”。
对于Nomad新手并试图整合Consul的人来说，一个主要的学习曲线是，这个人现在必须首先了解Consul是如何工作的，
部署一个Consul集群， 这在Nomad的新人之间产生了很多摩擦。Nomad 1.3解决了这个问题的一部分（即无需运行Consul即可发现基本服务），
非常适合刚开始使用基于Nomad的网络。但是，在这篇文章中，我想介绍一下我在生产中知道或使用过的所有不同的网络模式，
并尝试为Nomad初学者简化这些概念。

我将在我的开发计算机上运行单个节点 Nomad。可以在此处查看执行此操作的说明。

## 方案 1：在主机上公开应用程序

![](https://davidsche.github.io/blogs/images/2022/09/nomad_redis_dyn_port_illus.png)

我们将从一个简单的用例开始：你有一个redis容器，你想把它公开给主机，使用***docker run***命令就可以达成我们的预期：

```shell
docker run --rm -p=6379 redis:7
```

此指令公开主机上的动态端口。要查看端口号的确切含义，可以执行***docker ps***并在***PORTS***下面的找出类似的输出
*** 0.0.0.0:49153->6379/tcp *** 。

要验证是否正确，可以使用 redis-cli 连接到此主机：

```shell
$ redis-cli -p 49153                
127.0.0.1:49153> ping
PONG
```
匪夷所思！现在，让我们停止这个容器，看看我们如何在Nomad中做同样的事情。

```hcl

job "redis" {
  datacenters = ["dc1"]
  type        = "service"

  group "redis" {
    count = 1

    network {
      mode = "host"
      port "redis" {
        to = 6379
      }
    }

    task "redis" {
      driver = "docker"

      config {
        image = "redis:7"
        ports = ["redis"]
      }

      resources {
        cores  = 1
        memory = 256
      }
    }
  }
}

```
这是一个关于如何在nomad上运行 Redis 的部署定义，我们在这里不处理任何卷挂载，自定义配置等 - 我们的想法是只在Nomad中学习网络概念！

将上述文件另存为job.nomad并部署到群集：

```shell
nomad run job.nomad
```

在几行配置中，我们有一个Docker容器正在运行，它公开了一个动态端口：23522 。

![](https://davidsche.github.io/blogs/images/2022/09/nomad_redis_dynamic_port.png)

我们可以通过在主机上使用 redis-cli连接到它：

```shell
$ redis-cli -p 23522
127.0.0.1:23522> ping
PONG
```

注意：在您的版块中很重要。Nomad 将此信息传递给主机上运行的守护程序。因此，除非您指定要在容器中通告哪些端口，否则它将不知道是否公开 6379。portstask.configdocker

这可以通过以下方法轻松验证：docker inspect

```shell
# without `ports`
$ docker inspect fc32a4ffd148 -f "{{json .NetworkSettings.Ports }}" | jq '.'
{
"6379/tcp": null
}

# with `ports`
$ docker inspect 0421101d0228 -f "{{json .NetworkSettings.Ports }}" | jq '.'
{
  "6379/tcp": [
    {
      "HostIp": "127.0.0.1",
      "HostPort": "31930"
    }
  ],
  "6379/udp": [
    {
      "HostIp": "127.0.0.1",
      "HostPort": "31930"
    }
  ]
}
```

### 公开静态端口

一种不太常见的方案是将应用程序绑定到主机上的静态端口。稍后我们将介绍一个示例，说明您稍后何时想要执行此操作，但这通常不会被广泛使用，因为在集群中，您的应用程序可以“浮动”在周围，并且坚持端口的想法没有用。但是，我们有一种方法可以通过在块中添加一行来做到这一点：staticport

```hcl
    network {
      port "redis" {
        to     = 6379
        static = 6379
      }
    }

```

![](https://davidsche.github.io/blogs/images/2022/09/nomad_redis_static_port.png)

当我们再次部署同一文件时，我们可以看到端口分配已从动态端口更改为我们分配的静态端口。
您的工作是确保没有其他应用程序正在侦听相同的接口和端口，因为这必然会导致冲突。

## 场景 2：与同一组中的 Redis 通信

对于此方案，我们将假设有一个 Go 应用程序需要与 Redis 通信。但是，在这种情况下，Redis 有点像临时缓存，因此可以将它们部署在同一任务组中。

>> 如果您不知道任务和组之间的区别，这里有一个非常原始的解释，但请阅读文档以使其更清晰。

>> 一个组可以包含多个任务。这里需要了解的是，组将始终具有自己的共享网络命名空间。
>> 这意味着，如果组中有 2 个任务，则它们都将有权访问同一网络命名空间。这允许两个任务在同一网络接口上相互通信。

```hcl
job "hello" {
  datacenters = ["dc1"]
  type        = "service"

  group "app" {
    count = 1

    network {
      mode = "host"
      port "app" {
        to     = 8080
        static = 8080
      }
      port "redis" {
        to     = 6379
        static = 6379
      }
    }

    task "redis" {
      driver = "docker"

      config {
        network_mode = "host"
        image        = "redis:7"
        ports        = ["redis"]
      }

      resources {
        cores  = 1
        memory = 256
      }
    }


    task "app" {
      driver = "docker"
      env {
        DEMO_REDIS_ADDR = "${NOMAD_ADDR_redis}"
      }

      config {
        network_mode = "host"
        image        = "mrkaran/hello-app:1.0.0"
        ports        = ["app"]
      }

      resources {
        cores  = 1
        memory = 512
      }
    }
  }
}
```

**要点：**

 - 您可以看到我们在同一组(**app**)下定义了 **app**  任务（task）和**redis**任务。 这意味着Nomad将在同一客户端上部署这两个任务
  （因为它们往往不仅共享相同的网络命名空间，还共享一个公共分配目录 - 这使得跨任务共享文件变得非常容易）。
 - 我们正在使用**NOMAD_ADDR_redis**获取redis任务的IP：port 地址。这在运行时由Nomad注入。您可以在此处找到运行时变量的[列表](https://www.nomadproject.io/docs/runtime/environment)。
 - 这非常适合快速测试/开发设置，您不希望服务发现等的积压，并希望以尽可能少的摩擦连接到您的应用程序。

如果您要从基于docker-compose环境迁移，则上述配置是合适的，您可以将此模板用于您的服务。
这种方法的最大限制是它使用的是主机网络，因此不可能在其上设置任何类型的访问控制。
这实际上意味着，没有什么可以阻止群集上的任何其他应用程序与这些端口通信。

## 方案 3：跨不同组进行通信
如果您有相关任务（例如，要在任务开始之前提取文件的 init 任务），则任务组很有用。
但是使用的一个缺点是您无法独立扩展任务。在上面的示例中，我们将 Redis 和 App 放在同一组**group**中，
但这意味着如果增加同一组的**count**来扩展应用程序，则最终也会扩展 Redis 容器。这是不可取的，
因为 Redis 可能不会按比例扩展到应用。

创建多个组的方法是将任务拆分为各自的组：

```hcl
job "hello" {
  datacenters = ["dc1"]
  type        = "service"

  group "app" {
    count = 1

    network {
      mode = "host"
      port "app" {
        to     = 8080
        static = 8080
      }
    }

    task "app" {
      driver = "docker"
      env {
        DEMO_REDIS_ADDR = "localhost:6379"
      }

      config {
        image = "mrkaran/hello-app:1.0.0"
        ports = ["app"]
      }

      resources {
        cores  = 1
        memory = 512
      }
    }
  }

  group "redis" {
    count = 1

    network {
      mode = "host"
      port "redis" {
        to     = 6379
        static = 6379
      }
    }

    task "redis" {
      driver = "docker"

      config {
        image = "redis:7"
        ports = ["redis"]
      }

      resources {
        cores  = 1
        memory = 256
      }
    }
  }
}
```

提交此作业时，将获得2个分配ID（每个组创建一个**alloc**）。这里的关键点是这两个组都有自己的网络命名空间。
因此，我们实际上没有任何方法可以访问其他应用程序（我们不能真正依赖主机网络，因为无法保证这两个组将部署在同一节点上）。

在前面的示例中，我们了解了 Nomad 如何公开包含有关其他组中所有任务的信息的运行时变量。
但是现在由于这些组是分开的，app容器不知道redis（反之亦然）：

```shell
env | grep NOMAD
NOMAD_REGION=global
NOMAD_CPU_LIMIT=4700
NOMAD_IP_app=127.0.0.1
NOMAD_JOB_ID=hello
NOMAD_TASK_NAME=app
NOMAD_SECRETS_DIR=/secrets
NOMAD_CPU_CORES=1
NOMAD_NAMESPACE=default
NOMAD_ALLOC_INDEX=0
NOMAD_ALLOC_DIR=/alloc
NOMAD_JOB_NAME=hello
NOMAD_HOST_IP_app=127.0.0.1
NOMAD_SHORT_ALLOC_ID=a9da72dc
NOMAD_DC=dc1
NOMAD_ALLOC_NAME=hello.app[0]
NOMAD_PORT_app=8080
NOMAD_GROUP_NAME=app
NOMAD_PARENT_CGROUP=nomad.slice
NOMAD_TASK_DIR=/local
NOMAD_HOST_PORT_app=8080
NOMAD_MEMORY_LIMIT=512
NOMAD_ADDR_app=127.0.0.1:8080
NOMAD_ALLOC_PORT_app=8080
NOMAD_ALLOC_ID=a9da72dc-94fc-6315-bb37-63cbeef153b9
NOMAD_HOST_ADDR_app=127.0.0.1:8080
```

### 服务发现
这就是事情变得有趣的地方。app组需要先发现redis，然后才能连接到它。有多种方法可以做到这一点，但我们将介绍2种更常见的标准方法。

#### 使用Nomad本地服务发现

![](https://davidsche.github.io/blogs/images/2022/09/nomad_networking_inter_group_native.png)

这是Nomad 1.3中推出的一项功能。在此之前，Nomad不得不依靠领事来做到这一点。但是，随着Nomad中内置的本机服务发现，事情变得更加简单。
让我们对作业文件进行以下更改。在每个组中，我们将添加一个service定义：

```hcl
  group "app" {
    count = 1

    network {
      mode = "host"
      port "app" {
        to = 8080
      }
    }

    service {
      name     = "app"
      provider = "nomad"
      port     = "app"
    }
    // task is the same
  }

  group "redis" {
    count = 1

    network {
      mode = "host"
      port "redis" {
        to = 6379
      }
    }

    service {
      name     = "redis"
      provider = "nomad"
      port     = "redis"
    }
    // task is the same
  }
```

因此，我们添加了一个service代码并删除了static端口。好吧，当我们使用服务发现时，不需要绑定到静态端口。

提交作业后，我们可以使用**nomad service list**命令来确保服务已在Nomad注册。

```shell
nomad service list    
Service Name  Tags
app           []
redis         []
```

要了解有关特定服务的详细信息，我们可以使用**nomad service info**:

```shell
$ nomad service info app      
Job ID  Address          Tags  Node ID   Alloc ID
hello   127.0.0.1:29948  []    d92224a5  5f2ac51f
$ nomad service info redis
Job ID  Address          Tags  Node ID   Alloc ID
hello   127.0.0.1:22300  []    d92224a5  8078c9a6
```

完善！我们可以在每个服务中看到动态端口分配。要在我们的应用程序中使用此配置，我们将对其进行模板化：

```hcl
    task "app" {
      driver = "docker"

      template {
        data = <<EOH
{{ range nomadService "redis" }}
DEMO_REDIS_ADDR={{ .Address }}:{{ .Port }}
{{ end }}
EOH

        destination = "secrets/config.env"
        env         = true
      }

      config {
        image = "mrkaran/hello-app:1.0.0"
        ports = ["app"]
      }

      resources {
        cores  = 1
        memory = 512
      }
    }
```
我们添加了一个template 节，它将在容器中插值 env 变量。
我们循环访问nomadService并获取redis服务的地址和端口。这使得其他节点上的任务可以方便地发现彼此。

### 使用领事服务发现

![](https://davidsche.github.io/blogs/images/2022/09/nomad_networking_inter_group_consul.png)

只需在我们的service块调整provider，我们就可以使用Consul代理进行服务发现。

```hcl
    service {
      name     = "app"
      provider = "consul"
      port     = "app"
    }


    task "app" {
      driver = "docker"

      template {
        data = <<EOH
{{ range service "redis" }}
DEMO_REDIS_ADDR={{ .Address }}:{{ .Port }}
{{ end }}
EOH
        #... ...
      }
    }

```

>> 确保您正在运行领事，并已将Nomad连接到它。请参考文档。

由于现在我们用consul注册服务，因此我们必须循环service而不是nomadService。其余的东西几乎保持不变。
我真的很喜欢只需2行代码即可在Nomad/Consul之间切换以发现服务。

当然，现在使用领事有一定的优势：

 - 您可以使用 DNS 查询服务的地址：
```shell
doggo redis.service.consul @tcp://127.0.0.1:8600
NAME                    TYPE    CLASS   TTL ADDRESS     NAMESERVER     
redis.service.consul.   A       IN      0s  172.20.10.3 127.0.0.1:8600  

```
 - 定义运行状况检查。由于这是一项新功能，因此Nomad服务上的运行状况检查不存在，但存在相同的GitHub[问题](https://github.com/hashicorp/nomad/issues/12576)。
 - 可通过Nomad以外的应用程序访问。如果consul被Nomad集群以外的其他应用程序使用，他们仍然可以获取他们的地址（使用DNS或REST API）
  但是，Nomad本机服务发现非常适合本地设置，甚至是生产中的较小用例，因为它消除了在堆栈中运行Consul的需要，这是一件大事！

## 方案 4：限制对某些命名空间的访问

![](https://davidsche.github.io/blogs/images/2022/09/nomad_networking_consul_connect.png)

在上述所有情况下，我们发现服务公开给本地 Nomad 客户端。如果您在集群上运行多个命名空间，则根本不希望公开它们。
此外，您可能希望对哪个应用程序可以访问特定服务表示细粒度的控制。所有这些都可以通过**Service Mesh**实现。
Nomad提供了一种通过**Consul Connect**拥有“服务网格”的方法。**Consul Connect**可以执行 mTLS 和服务授权。
在引擎盖下，它是一个与您的应用程序一起运行的 Envoy proxy（sidecar 是一种奇特的说法）。
consul代理为您配置 Envoy 配置，因此一切都非常无缝。

为此，我们首先需要的是bridge网络模式。此网络模型实际上是一个 CNI 插件，需要在/opt/cni/bin中单独安装。请按照[此处](https://www.nomadproject.io/docs/integrations/consul-connect)提到的步骤操作。

```hcl
    network {
      mode = "bridge"
      port "redis" {
        to = 6379
      }
    }
```

redis中的服务称为**Consul 连接入口**(Consul Connect Ingress ):

```hcl
    service {
      name     = "redis"
      provider = "consul"
      port     = "6379"
      connect {
        sidecar_service {}
      }
    }
```

这是一个空块，因为我们不需要在这里定义任何上游。其余值将是默认值。

接下来，我们为我们的创建一个服务，即Consul连接出口：app
```hcl
    service {
      name     = "app"
      provider = "consul"
      port     = "app"
      connect {
        sidecar_service {
          proxy {
            upstreams {
              destination_name = "redis"
              local_bind_port  = 6379
            }
          }
        }
      }
    }
```

在这里，我们为 定义了一个上游。如果您仔细注意，我们正在使用Consol连接入口中的端口号。
由于某种原因，如果您使用命名端口而不是6379，则它不起作用。我不完全确定这是一个错误还是打算像这样工作。redis

因此，在这里，当想要与redis 交互时，它会链接localhost:6379与特使边车正在收听的本地端谈。我们可以使用netstat验证：app

```shell
$ netstat -tulpvn
Active Internet connections (only servers)
Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    
tcp        0      0 127.0.0.2:19001         0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:23237           0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:6379          0.0.0.0:*               LISTEN      -                   
tcp6       0      0 :::8080                 :::*                    LISTEN      1/./hello.bin
```

流量从此端口发送到它通告的端口上的另一个 Envoy 代理（ Consul 自动配置）。该 Envoy 代理进一步将流量发送到端口 6379 上的redis容器。
代理流量通过mTLS安全加密并授权（通过Consul Intentions（意图） - 本文未涉及）。

## 方案 5：向最终用户公开服务

![图像](https://davidsche.github.io/blogs/images/2022/09/nomad_networking_user_facing.png)

在第一个场景中，我们讨论了使用静态端口。好吧，事实证明，如果您想定义流量入口服务，那将非常有用。
与K8s不同，Nomad没有任何入口控制器，因此最好的方法是将这些Web代理作为系统作业部署在每个节点上（这意味着它确保在每个客户端节点上运行），
并将它们绑定到静态端口（例如443/80）。然后，配置负载均衡器并将所有 Nomad 节点注册为目标 IP，其端口将是您定义的静态端口。
然后，这些入口代理（如 HAProxy/Nginx）可用于通过我们上面提到的任何模式与您的应用程序进行通信。

通常，您希望对入口代理使用“基于主机”的路由模式来做出路由决策。

例如，如果您有指向ALB的**a.example.org** DNS记录。现在，当请求到达ALB时，它会转发给任何一个NGINX/HA代理。
要使 HAProxy 将流量正确路由到“服务”，可以使用“Host”头标记。

## 总结

这些是我所知道的一些常见的网络模式。由于其中一些概念并不简单，我希望解释有助于澄清一些问题。

这个主题还有很多内容，例如Consul网关和多种CNI，它们调整了网络在集群中发生的方式，
但这些是一些非常高级的主题，超出了本文的范围。

[原文](https://mrkaran.dev/posts/nomad-networking-explained/)
